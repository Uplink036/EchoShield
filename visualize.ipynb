{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"metrics_stft.csv\")\n",
    "\n",
    "# Add index column\n",
    "metrics[\"index\"] = metrics.index\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data, with the x-axis being the number of epochs and the y-axis being the scores of reward, audio_sim and transcription_sim\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set(xlabel=\"Epochs\", ylabel=\"Scores\")\n",
    "plt.title(\"Scores over epochs\", fontsize=20)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.locator_params(axis='x', integer=True)\n",
    "\n",
    "data = metrics.melt('index', var_name='score', value_name='value')\n",
    "sns.lineplot(x='index', y='value', hue='score', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELAY = 100\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 8), sharex=True)\n",
    "fig.suptitle('MODEL DDPG Training Results')\n",
    "\n",
    "sns.lineplot(ax=axes[0], x=\"index\", y=\"reward\", data=metrics, color=\"r\", alpha= 0.4)\n",
    "reward_mean = [np.mean(metrics[\"reward\"][i-DELAY:i]) for i in range(DELAY, len(metrics))]\n",
    "sns.lineplot(ax=axes[0], x=range(DELAY, len(metrics)), y=reward_mean, color=\"black\")\n",
    "axes[0].set_ylabel(\"Reward\")\n",
    "\n",
    "sns.lineplot(ax=axes[1], x=\"index\", y=\"transcription_sim\", data=metrics, color=\"g\", alpha= 0.4)\n",
    "transcription_mean = [np.mean(metrics[\"transcription_sim\"][i-DELAY:i]) for i in range(DELAY, len(metrics))]\n",
    "sns.lineplot(ax=axes[1], x=range(DELAY, len(metrics)), y=transcription_mean, color=\"black\")\n",
    "axes[1].set_ylabel(\"Transcription Similarity\")\n",
    "\n",
    "sns.lineplot(ax=axes[2], x=\"index\", y=\"audio_dissim\", data=metrics, color=\"b\", alpha= 0.4)\n",
    "audio_mean = [np.mean(metrics[\"audio_dissim\"][i-DELAY:i]) for i in range(DELAY, len(metrics))]\n",
    "sns.lineplot(ax=axes[2], x=range(DELAY, len(metrics)), y=audio_mean, color=\"black\")\n",
    "axes[2].set_ylabel(\"Audio Dissimilarity\")\n",
    "\n",
    "axes[2].set_xlabel(\"Iteration\")\n",
    "\n",
    "# Align y-axis labels\n",
    "fig.align_ylabels()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A latex table showing mean, std for each of the areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_table_mean = metrics[\"reward\"].mean()\n",
    "reward_table_std  = metrics[\"reward\"].std()\n",
    "\n",
    "trans_table_mean = metrics[\"transcription_sim\"].mean()\n",
    "trans_table_std  = metrics[\"transcription_sim\"].std()\n",
    "\n",
    "dissim_table_mean = metrics[\"audio_dissim\"].mean()\n",
    "dissim_table_std  = metrics[\"audio_dissim\"].std()\n",
    "\n",
    "POI = 2\n",
    "\n",
    "table_start =   \"\\\\begin{table}[h!]\\n\" + \\\n",
    "                \"   \\\\begin{center}\\n\" + \\\n",
    "                \"   \\\\begin{tabular}{ c || c |  c }\\n\" + \\\n",
    "                \"       Metric & mean & Standard Deviation \\\\\\\\\\\\hline\\n\"\n",
    "\n",
    "table_content = f\"       Reward & {round(reward_table_mean, POI)} & {round(reward_table_std, POI)}\\\\\\\\\\n\" + \\\n",
    "                f\"       Transcription Similarity & {round(trans_table_mean, POI)} & {round(trans_table_std, POI)}\\\\\\\\\\n\" + \\\n",
    "                f\"       Audio Dissimilarity & {round(dissim_table_mean, POI)} & {round(dissim_table_std, POI)}\\\\\\\\\\n\"\n",
    "\n",
    "table_end =     \"   \\\\end{tabular}\\n\" + \\\n",
    "                \"   \\\\caption{Caption}\\n\" + \\\n",
    "                \"   \\\\label{table:Table}\\n\" + \\\n",
    "                \"   \\\\end{center}\\n\" + \\\n",
    "                \"\\\\end{table}\\n\"\n",
    "print(table_start + table_content + table_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('metrics_compare.csv')\n",
    "# Remove audio_path\n",
    "data.drop('audio_path', axis=1, inplace=True)\n",
    "data.groupby('attack_type').mean()\n",
    "\n",
    "#Normalize the data (audio_distance and similarity)\n",
    "data['Audio Dissimilarity'] = data['audio_distance'] / data['audio_distance'].max()\n",
    "data['Transcription Similarity'] = data['similarity']\n",
    "\n",
    "data.drop(\"similarity\", axis=1,inplace=True) \n",
    "data.drop(\"audio_distance\", axis=1,inplace=True) \n",
    "\n",
    "# Rename sucess to Sucess\n",
    "data[\"Success\"] = data[\"success\"]\n",
    "data.drop(\"success\", axis=1,inplace=True) \n",
    "\n",
    "data = data.melt(id_vars=['attack_type'], value_vars=['Transcription Similarity', 'Audio Dissimilarity', 'Success'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.catplot(x='attack_type', \n",
    "                y='value', \n",
    "                hue='variable', \n",
    "                data=data, \n",
    "                kind='bar', \n",
    "                height=6, \n",
    "                aspect=1.5,\n",
    "                palette=\"Set2\")\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_db = pd.read_csv(\"defence/classify_detect_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classify_db.to_latex(index=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_db = pd.read_csv(\"defence/compare_detect_results.csv\")\n",
    "compare_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "table_start =   \"\\\\begin{table}[h!]\\n\" + \\\n",
    "                \"   \\\\begin{center}\\n\" + \\\n",
    "                \"   \\\\begin{tabular}{ c || c c c c}\\n\"\n",
    "table_end =     \"   \\\\end{tabular}\\n\" + \\\n",
    "                \"   \\\\caption{Caption}\\n\" + \\\n",
    "                \"   \\\\label{table:Table}\\n\" + \\\n",
    "                \"   \\\\end{center}\\n\" + \\\n",
    "                \"\\\\end{table}\\n\"\n",
    "\n",
    "cmap = sns.color_palette(\"light:b\", as_cmap=True)\n",
    "for index in compare_db.index:\n",
    "     fig, axes = plt.subplots()\n",
    "     row = compare_db.loc[index]\n",
    "     name = row[\"Attack\"]\n",
    "     name = name.translate({ord('_'): ' [', ord('/'): ']'})\n",
    "     label = f\"{name.capitalize()} Using Whisper and Google Speech Recognition as Defence\"\n",
    "     fig.supxlabel(\"Predicted label\")\n",
    "     fig.supylabel(\"True Label\")\n",
    "     axes.set_title(label)\n",
    "     sns.heatmap([[row[\"FN\"], row[\"FP\"]], [row[\"TN\"],row[\"TP\"]] ], annot=True, fmt=\".0f\", ax=axes, cmap=cmap)\n",
    "     plt.show()\n",
    "\n",
    "print(table_start, end=\"\")\n",
    "print(\"\\tAttack & Accuracy & Precision & Recall & F1\\\\\\\\\\\\hline\\n\", end='')\n",
    "for index in compare_db.index:\n",
    "     row = compare_db.loc[index]\n",
    "     name = row[\"Attack\"]\n",
    "     name = name.translate({ord('_'): ' ', ord('/'): ''})\n",
    "     name = name.split(sep=' ')[1]\n",
    "     print(f\"\\t{name} & {row['Accuracy']} & {row['Precision']} & {row['Recall']} & {row['F1']} \\\\\\\\\\n\", end=\"\")\n",
    "print(table_end)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
